{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/teocons2003/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Small LSTM Network to Generate Text for Alice in Wonderland\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback, Callback\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#encoder stuff\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "\n",
    "from gensim.models.wrappers import FastText as FastTextWrapper\n",
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper params\n",
    "seq_length = 17\n",
    "img_embedding = 300\n",
    "nr_input_lines = 5000 # used to determine steps_per_epoch (nr batches)\n",
    "photos_per_batch = 5 # a batch will consists of photos_per_batch photos (each photo has 20-30 text samples)\n",
    "lstm_cell = 128\n",
    "examples_train = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3722\n",
      "6689\n"
     ]
    }
   ],
   "source": [
    "filepath = \"dataset_txt/Flickr8k.lemma.token.txt\"\n",
    "fast_text = \"fastText_eng/wiki.simple\"\n",
    "dir_imgs = \"dataset_img\"\n",
    "token_start = 'sstart'\n",
    "token_end = 'eend'\n",
    "special_token = 'xx'\n",
    "# load fast text - takes a lot of time\n",
    "model_embeddings = FastTextWrapper.load_fasttext_format(fast_text)\n",
    "# some initial info about whole dataset\n",
    "def get_initial_info_data(filepath):\n",
    "    \n",
    "    global examples_train\n",
    "    token_set = set()\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            #print(line.split(' ')[0].split('#')[0])\n",
    "            txt = \" \".join(line.split(' ')[1:])\n",
    "            tokens = nltk.word_tokenize(txt)\n",
    "            examples_train += len(tokens) + 1\n",
    "            for token in tokens:\n",
    "                token_set.add(token.lower())\n",
    "    token_list = list(token_set)\n",
    "    token_list.insert(0, special_token)\n",
    "    token_list.append(token_start)\n",
    "    token_list.append(token_end)\n",
    "    token_to_int = dict((token, i) for i, token in enumerate(token_list))\n",
    "    int_to_token = dict((i, token) for i, token in enumerate(token_list))\n",
    "    return token_to_int, int_to_token, len(token_to_int)\n",
    "\n",
    "token_to_int, int_to_token, n_vocab = get_initial_info_data(filepath)\n",
    "print(token_to_int['build'])\n",
    "print(len(token_to_int))\n",
    "# print(model_embeddings.wv['take'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.48571461e-01 -2.35421494e-01 -1.42850086e-01 -3.43478203e-01\n",
      "  5.09257312e-04 -9.10188928e-02 -6.53988481e-01  5.78893945e-02\n",
      "  1.20438114e-01 -5.93623042e-01  1.64768830e-01  1.88641116e-01\n",
      " -1.50691509e-01  2.48401672e-01 -1.65533170e-01 -1.03597499e-01\n",
      " -1.06646709e-01 -1.50174588e-01 -3.49323004e-01  2.44464993e-01\n",
      "  5.34847438e-01 -1.18374132e-01  2.79681861e-01 -9.53332428e-03\n",
      "  3.37124377e-01  1.58020392e-01 -1.48747519e-01  2.42728367e-01\n",
      " -2.84381092e-01 -3.69370431e-01 -1.71083584e-01  1.74123153e-01\n",
      "  2.61685196e-02  1.70245796e-01 -3.42596024e-01 -1.70652315e-01\n",
      "  7.97651634e-02  2.29811408e-02  2.09442779e-01  5.59639223e-02\n",
      "  2.48766020e-01 -4.16914135e-01 -1.38790101e-01 -1.25998765e-01\n",
      " -8.44580084e-02  1.01453118e-01 -2.05464751e-01  1.49973124e-01\n",
      "  4.03368399e-02  3.33950520e-01 -1.30867019e-01  8.89239684e-02\n",
      " -1.45947486e-01 -9.97177884e-02 -3.67225647e-01 -9.82636437e-02\n",
      "  3.12037379e-01  4.06918854e-01  3.09091091e-01 -9.07902718e-02\n",
      " -6.06327534e-01  9.42307636e-02  2.95654029e-01 -3.27895246e-02\n",
      " -2.54838288e-01  2.89684504e-01  5.33280484e-02 -1.77630752e-01\n",
      "  3.54240052e-02  1.97695240e-01 -9.56374332e-02  1.72127604e-01\n",
      " -4.84638155e-01  3.71309742e-02  1.02859683e-01 -4.61544655e-02\n",
      " -1.95194498e-01 -4.06638294e-01 -3.91022488e-02 -1.86049014e-01\n",
      "  1.22257419e-01 -3.04572642e-01 -2.80869722e-01  2.13980153e-01\n",
      " -4.08284456e-01  1.01292677e-01  4.40065295e-01 -2.98144631e-02\n",
      "  3.26807722e-02 -1.85735390e-01  1.25684708e-01 -1.33263201e-01\n",
      "  2.44114012e-01 -3.29579204e-01  3.47049147e-01  4.03064452e-02\n",
      " -1.13724813e-01  1.89589024e-01  3.81453931e-01 -2.07501613e-02\n",
      "  1.83487386e-01 -1.96837053e-01  4.25202176e-02  3.87279004e-01\n",
      " -3.44210684e-01  3.16275865e-01 -6.37053605e-03 -1.22789301e-01\n",
      "  1.96397334e-01 -3.57100070e-01 -3.61895502e-01  4.16065037e-01\n",
      "  2.81549152e-02 -1.68401450e-01  1.40522838e-01 -2.44893767e-02\n",
      " -8.43163058e-02  3.35893452e-01 -6.86817691e-02 -1.95155777e-02\n",
      "  4.39036712e-02  2.03952361e-02 -1.68078899e-01  2.22212244e-02\n",
      " -2.49600843e-01 -2.44778171e-01  2.65898168e-01  2.15315238e-01\n",
      "  5.97646758e-02 -5.91613986e-02  2.22594574e-01  5.90285435e-02\n",
      " -2.42080688e-01  1.88174676e-02  1.77581355e-01  3.39261353e-01\n",
      " -7.61164278e-02  8.39443579e-02  1.24332078e-01  4.87976633e-02\n",
      " -5.93314730e-02  7.21554339e-01  4.08093855e-02  3.56912822e-01\n",
      "  2.50841945e-01 -1.28624305e-01 -2.31781110e-01 -8.98188874e-02\n",
      " -2.35154033e-01  2.80625820e-01 -1.50568470e-01 -6.62578270e-02\n",
      "  1.10000707e-01  4.35862511e-01  5.53909123e-01  2.62169391e-01\n",
      " -4.15395409e-01  1.45975664e-01  2.94626892e-01  3.51142138e-01\n",
      "  2.72322625e-01 -1.64535522e-01  6.76211417e-02 -2.89216757e-01\n",
      "  1.94189042e-01  2.65569150e-01 -1.64669782e-01 -3.95311028e-01\n",
      "  1.39198601e-01 -8.75820071e-02 -5.92047982e-02  1.75941177e-02\n",
      "  5.10483719e-02  3.42319727e-01 -1.03718922e-01  1.18199490e-01\n",
      "  3.46443474e-01 -4.64711398e-01 -1.57452509e-01  2.27366582e-01\n",
      " -3.79457027e-01  3.52573574e-01  2.09451243e-01 -6.33943751e-02\n",
      "  2.73329109e-01 -2.14716345e-01 -7.16861859e-02 -8.57850090e-02\n",
      " -4.27094251e-01 -2.30447054e-02 -5.45288883e-02  1.70961589e-01\n",
      "  2.83405125e-01 -1.17123969e-01 -2.13994101e-01 -2.15908498e-01\n",
      " -8.77414048e-01  3.30016196e-01 -1.22849785e-01 -1.25333622e-01\n",
      "  2.83896148e-01  5.58093488e-01  3.54046434e-01  1.99997678e-01\n",
      "  3.08095217e-01  3.75954024e-02  8.31310749e-02 -2.12374404e-01\n",
      " -2.78871357e-01 -1.14796810e-01 -1.47693038e-01  4.75841105e-01\n",
      "  5.76665461e-01 -5.85410837e-03  9.11055654e-02 -3.16418618e-01\n",
      " -4.24699038e-01 -1.32585362e-01 -3.58066298e-02  1.58999749e-02\n",
      " -4.07214969e-01 -1.20657422e-01 -2.03140393e-01 -2.34961808e-02\n",
      " -1.66532382e-01 -1.10049628e-01  1.35893107e-03 -1.35450512e-01\n",
      " -5.63174367e-01  4.93287295e-01 -1.41914468e-02  2.41315961e-01\n",
      " -1.71373978e-01  7.37533048e-02  1.17825441e-01 -2.55081952e-01\n",
      "  5.96276596e-02  1.68144852e-01 -3.56523424e-01 -1.27926722e-01\n",
      "  2.07219556e-01  2.91556090e-01 -2.13528182e-02  8.75937112e-04\n",
      "  2.59324282e-01  2.68274415e-02 -2.07862034e-01 -5.29025197e-01\n",
      "  1.92176506e-01  4.34858114e-01  1.48000553e-01  5.15748799e-01\n",
      "  1.19353220e-01 -8.17458108e-02 -3.57677251e-01 -1.18715383e-01\n",
      "  7.97851756e-02 -1.80461407e-01  3.62837821e-01 -2.45775655e-01\n",
      " -1.51285008e-01 -2.64184445e-01 -3.33687991e-01  3.70277107e-01\n",
      "  5.91242127e-02  1.63171768e-01  3.55014652e-01 -4.33003217e-01\n",
      "  1.61430880e-01 -6.22275710e-01 -2.50555128e-01 -2.40593180e-01\n",
      "  7.56508484e-02  1.29998326e-01  4.79271710e-01 -1.47842929e-01\n",
      "  8.55035614e-03 -1.23814844e-01  2.10402876e-01  4.68180239e-01\n",
      "  1.87943950e-01  2.23866273e-02  4.15971488e-01 -1.82529181e-01\n",
      " -2.27109417e-01  1.18544921e-01  4.47819769e-01  2.28212774e-03\n",
      " -4.09676582e-01  2.21093819e-01 -8.23210105e-02 -3.95082682e-01\n",
      " -2.49535650e-01 -2.26156473e-01 -4.95539382e-02  4.04938668e-01\n",
      " -9.48991627e-02 -5.75330928e-02  2.19455719e-01 -1.75242662e-01]\n",
      "[ 0.517553   -0.24412666  0.21304104 -0.06015646 -0.20797522  0.03572382\n",
      " -0.61099875  0.36157104  0.44725662 -0.4028541   0.14682321  0.20897174\n",
      "  0.13551868 -0.23674175 -0.45632786 -0.6981878  -0.03968194 -0.18242982\n",
      " -0.5489946   0.34452567  0.4107274   0.79205465 -0.26191252 -0.288548\n",
      " -0.29908448 -0.11246701  0.17503333  0.15475501  0.20714627 -0.27820712\n",
      "  0.04167736 -0.33297554 -0.14630659  0.8360816   0.1020451  -0.2088699\n",
      "  0.08048473  0.08513898 -0.04820034  0.0668584   0.17937414 -0.30570623\n",
      "  0.33787483 -0.25160453 -0.03162396  0.04491204 -0.7058882   0.3649676\n",
      " -0.41807574 -0.32404128  0.16778338  0.36219817 -0.47371677  0.13326284\n",
      " -0.6370731  -0.08706427 -0.11232453 -0.36510605  0.2163667  -0.31234005\n",
      " -0.03426564  0.00160531  0.23418747  0.14769994  0.4430299   0.44748542\n",
      " -0.2567183   0.44337773  0.14366351  0.05312983 -0.13376448  0.06692552\n",
      "  0.21265745 -0.12735108 -0.04157584  0.19360375 -0.399863   -0.26748392\n",
      "  0.37419632  0.1246144  -0.00919218 -0.48359087  0.13388611 -0.16245751\n",
      " -0.41252342  0.24820209  0.25858933 -0.08308612  0.03341205 -0.37124413\n",
      " -0.06401258 -0.14768805  0.1251552  -0.05399368  0.4158819  -0.15724337\n",
      " -0.0674229   0.4088727   0.38301396 -0.00784824  0.39817595 -0.38571173\n",
      " -0.5015264   0.06108175 -0.38949022  0.14853294 -0.01085455 -0.16820018\n",
      " -0.03566819 -0.10056186 -0.46535793 -0.03384391 -0.09647466  0.01428581\n",
      "  0.06916568 -0.33114544 -0.13730134  0.32591096  0.43630832  0.27073613\n",
      " -0.05475215 -0.1683762  -0.0327628  -0.07315166  0.14403407 -0.67563534\n",
      " -0.05106254  0.02709086 -0.10628267  0.02777898  0.25299647  0.01956956\n",
      " -0.09401254  0.28183943 -0.37654847  0.0394084   0.13478656 -0.2580913\n",
      "  0.10660839 -0.20123482  0.00671848  0.5345437  -0.23490989  0.15611216\n",
      " -0.13641916  0.09997099 -0.21283694 -0.01682539 -0.3465794  -0.07512315\n",
      " -0.1452036  -0.01059669  0.4356127  -0.03215242  0.62598854  0.14866444\n",
      " -0.0262156   0.70444494  0.64331883  0.54637873  0.3582556  -0.12541583\n",
      " -0.1183977  -0.28687504 -0.2879231   0.20025854  0.1995149  -0.05870123\n",
      "  0.17133148  0.06378738  0.14946215 -0.15293597  0.17346647  0.3134033\n",
      "  0.02992045  0.20188563  0.34473395  0.11459558 -0.04973221  0.13552211\n",
      " -0.5831488   0.31342083 -0.3884665   0.26802644  0.09278888 -0.27127898\n",
      " -0.18378547  0.13822146 -0.0202916  -0.1016329   0.13564838 -0.14666076\n",
      "  0.19210863 -0.43312338  0.02010075 -0.17415085 -0.66145676  0.09269615\n",
      "  0.02461387 -0.13630176  0.66202325  0.21728627  0.01556272  0.52739227\n",
      " -0.11494099 -0.20509052 -0.36997798 -0.44122124 -0.33636573  0.10547111\n",
      " -0.7054797   0.11345299  0.0781361  -0.18553498  0.04470137 -0.04920158\n",
      "  0.09757992  0.13773727 -0.27948356  0.3121778   0.4513184   0.20068109\n",
      " -0.44326773  0.39964056  0.12135901 -0.38478348 -0.29518208  0.5214376\n",
      " -0.092218    0.37645218  0.2054704   0.69525576  0.35440096  0.19464149\n",
      " -0.44289282 -0.4304336   0.00137857 -0.23253547  0.10930932 -0.08479859\n",
      "  0.4401923   0.07410506 -0.15884243 -0.32321382  0.6485321  -0.6446001\n",
      "  0.42317656 -0.42828578 -0.06596176  0.23301728 -0.16360521  0.5968157\n",
      " -0.09338712  0.19613636 -0.03243464 -0.61374646  0.0158343   0.3403749\n",
      "  0.10556906  0.22482644  0.5283385  -0.0078746  -0.06760757  0.31667814\n",
      "  0.7414931   0.00409956  0.2383931  -0.5289611   0.53558075 -0.4086089\n",
      "  0.20559607  0.34669933  0.03129904  0.27718577  0.08116678 -0.04593515\n",
      " -0.3022042   0.6532892   0.17636588 -0.27181867  0.06168775 -0.07206183\n",
      " -0.26973015 -0.62257653  0.45488074 -0.21025054  0.05836584  0.17257902\n",
      " -0.8506576   0.06632565  0.02080439 -0.33976826 -0.329971   -0.0128937\n",
      " -0.06024688  0.30996403  0.18917473  0.3762702   0.06279121  0.19857226]\n",
      "[ 1.95095897e-01 -2.83998340e-01 -1.30184710e-01  1.44015566e-01\n",
      "  4.53671783e-01  2.96221852e-01  4.72561955e-01 -1.45570308e-01\n",
      "  1.84705704e-01  5.97324550e-01  2.19789445e-01 -4.46724504e-01\n",
      " -5.40137768e-01  5.38960099e-01 -2.42758870e-01 -3.81377906e-01\n",
      " -6.38791084e-01  5.74014112e-02  8.59374225e-01  5.25679365e-02\n",
      "  2.51567930e-01  2.52664089e-01 -2.97491550e-01 -5.38459606e-02\n",
      "  8.14010799e-02  6.92347050e-01  4.62992609e-01 -3.71101052e-01\n",
      "  2.81820327e-01  1.02417730e-01  4.24732566e-01 -4.34810847e-01\n",
      " -5.59895754e-01  2.26890907e-01  2.86616415e-01 -2.13969387e-02\n",
      "  1.96223781e-02  1.63787901e-01  1.59164697e-01 -1.79668456e-01\n",
      "  3.07767123e-01 -1.85732633e-01 -4.45845306e-01 -1.13298386e-01\n",
      "  4.51800406e-01 -1.69457018e-01  1.34264529e-01  3.57817858e-01\n",
      "  5.14316082e-01 -8.54083225e-02 -3.29303741e-01 -5.38757026e-01\n",
      "  3.08432430e-01 -2.05307379e-01 -1.86865792e-01  5.94978750e-01\n",
      "  1.50173515e-01  2.27958649e-01 -5.00710495e-02 -2.15993181e-01\n",
      " -1.37364760e-01 -4.02767837e-01  4.10575718e-01 -1.13104656e-01\n",
      "  4.26936984e-01 -4.40256715e-01  5.61524391e-01  4.51629519e-01\n",
      " -1.44914001e-01 -1.79396197e-02  2.29773503e-02  1.31239906e-01\n",
      " -3.52288485e-01  9.43858176e-02  1.60413072e-01 -5.66342294e-01\n",
      " -2.23065391e-01  2.38290459e-01  1.83859915e-01 -1.82687398e-02\n",
      "  1.75839454e-01 -6.05138302e-01 -4.52481657e-01  4.97549057e-01\n",
      " -3.27812821e-01  2.53762603e-01 -1.20463982e-01 -2.79070228e-01\n",
      "  1.88944936e-02 -3.59770119e-01 -2.21933350e-01 -1.54548079e-01\n",
      "  2.03212887e-01 -3.71930987e-01  3.39607239e-01  1.12331636e-01\n",
      "  7.73773193e-02  7.75496960e-01  2.15381444e-01 -6.72432780e-01\n",
      "  2.88087875e-02  2.99924791e-01  4.22374785e-01  2.20397845e-01\n",
      " -4.97837096e-01  1.67890698e-01 -3.41161907e-01  2.23841012e-01\n",
      "  2.34860986e-01 -4.77185637e-01 -3.35607044e-02 -5.25774062e-03\n",
      "  1.89998507e-01 -9.86258984e-01  7.26764500e-01 -5.70087552e-01\n",
      " -9.86991078e-02 -3.11121106e-01 -1.78571805e-01  5.70004880e-01\n",
      "  1.38084695e-01  3.34484726e-01  1.20169908e-01 -2.39345312e-01\n",
      "  2.66575187e-01 -3.16397756e-01 -2.13291422e-02 -3.50534022e-02\n",
      "  1.10835351e-01  5.24846166e-02 -4.66577739e-01 -5.87791145e-01\n",
      " -7.11306930e-01  4.04238254e-02  3.75609279e-01 -2.54088044e-01\n",
      " -3.54113340e-01  1.91739589e-01  6.33324444e-01  3.46479982e-01\n",
      " -9.56350327e-01  1.06650305e+00  8.70675892e-02  9.98232245e-01\n",
      " -7.63914660e-02 -2.84967691e-01  1.65566489e-01 -3.59702706e-01\n",
      " -7.15273380e-01 -3.87141734e-01 -2.98120409e-01  2.50720680e-01\n",
      "  2.70777255e-01  1.93950608e-02  4.62629855e-01  4.91368055e-01\n",
      " -2.76015848e-01  2.48147160e-01  1.59835547e-01 -7.10038096e-03\n",
      " -2.43838400e-01 -2.35990062e-01 -2.46246591e-01  5.18900119e-02\n",
      " -5.48593253e-02  4.87789288e-02  4.50415343e-01 -7.36246943e-01\n",
      " -1.81764066e-01  4.31599677e-01 -1.69858739e-01  2.52212942e-01\n",
      " -5.09958267e-02  3.97603035e-01  2.65812635e-01 -4.04513150e-01\n",
      "  3.38020742e-01 -2.11760461e-01 -5.39553583e-01 -3.53495359e-01\n",
      " -8.44447315e-01  5.69645762e-01 -5.35399653e-02  4.61339444e-01\n",
      " -8.92611623e-01 -3.80725533e-01  2.07952261e-01  2.99637504e-02\n",
      " -1.95593983e-01 -3.97377551e-01 -3.65756780e-01 -3.01763296e-01\n",
      " -5.12753054e-02 -2.86194623e-01  1.89406574e-01 -2.50882208e-01\n",
      " -9.56634164e-01 -2.58011147e-02 -1.00614071e-01 -9.82638001e-01\n",
      "  3.29916418e-01  2.42676556e-01 -3.19677182e-02  4.38084394e-01\n",
      " -2.92495698e-01  1.50890440e-01 -2.81910598e-01 -1.38556257e-01\n",
      " -4.01063591e-01 -6.51121199e-01 -5.47771692e-01  7.54437268e-01\n",
      " -1.58309817e-01 -5.82714736e-01  2.50264972e-01  1.74988776e-01\n",
      "  1.08590521e-01 -2.43656516e-01 -3.20369899e-02 -1.40426591e-01\n",
      " -2.54353166e-01  1.68447509e-01 -3.33636940e-01  2.62180388e-01\n",
      "  2.03869209e-01  1.62989311e-02  5.82632348e-02 -3.77229154e-01\n",
      " -4.43228155e-01 -5.32268167e-01 -3.83543551e-01  1.95860773e-01\n",
      "  3.09647381e-01 -4.13629025e-01 -3.63475174e-01 -7.92690217e-01\n",
      " -2.07034379e-01 -5.25110625e-02 -7.60557234e-01  1.25754327e-01\n",
      " -2.75419742e-01  2.56304383e-01  7.84289911e-02 -7.74120539e-02\n",
      " -3.35736096e-01 -9.42652822e-02  2.70964921e-01 -5.08155227e-02\n",
      " -4.83523846e-01 -6.57526404e-02  7.43864104e-04  4.62628275e-01\n",
      " -2.77002573e-01  2.39314958e-01  4.16796654e-03  3.28818485e-02\n",
      "  3.72090518e-01 -6.48150146e-01 -2.74598509e-01  1.85766250e-01\n",
      "  1.17689364e-01 -4.27989215e-01 -4.21318263e-01  1.83542505e-01\n",
      "  2.56154180e-01 -4.94761989e-02  2.38879248e-02  9.55131650e-02\n",
      "  8.00535977e-01  2.51598582e-02 -6.50494099e-01  3.31224203e-01\n",
      "  3.60842824e-01 -4.69935656e-01  5.10579944e-01  2.07240969e-01\n",
      " -5.61298251e-01 -1.46251634e-01  6.14237040e-02  6.30497575e-01\n",
      "  4.98834670e-01 -2.68960893e-01 -2.48924628e-01  2.98421174e-01\n",
      "  2.37412870e-01 -5.01971617e-02  1.78868353e-01  7.88665891e-01\n",
      " -7.26420581e-02  4.85464036e-01 -3.24390709e-01  5.67703731e-02\n",
      " -5.24898246e-02  2.29569376e-01 -3.85655835e-02 -4.61665466e-02\n",
      "  2.01583818e-01  5.23317933e-01  1.83135346e-01 -1.45578623e-01]\n"
     ]
    }
   ],
   "source": [
    "print(model_embeddings.wv[token_start])\n",
    "print(model_embeddings.wv[token_end])\n",
    "print(model_embeddings.wv[special_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# input generator (in batches)\n",
    "# different batches may have different sizes\n",
    "# each beach has photos_per_batch photos, each photo with many text samples\n",
    "\n",
    "\n",
    "# VGG model for image feature extraction\n",
    "base_model = VGG16(weights='imagenet')\n",
    "base_model.layers.pop()\n",
    "print(base_model.summary())\n",
    "last_layer = base_model.layers[-1].output\n",
    "img_features = Dense(img_embedding)(last_layer)\n",
    "vgg_model = Model(inputs = base_model.input, outputs = img_features)\n",
    "\n",
    "def generate_image_features(img_name):\n",
    "    # Set up path for the image\n",
    "    try:\n",
    "        filename = dir_imgs + '/' + img_name\n",
    "        # The container of the images (VGG receives 224 x 224 x 3 tensors)\n",
    "        npix = 224\n",
    "        target_size = (npix,npix,3)\n",
    "        data = np.zeros((20,npix,npix,3))\n",
    "        image = load_img(filename, target_size=target_size)\n",
    "        image = img_to_array(image)\n",
    "        nimage = preprocess_input(image)\n",
    "        #batch size = 1 for now\n",
    "        batch_size = 1\n",
    "        y_pred = vgg_model.predict(nimage.reshape( (batch_size,) + nimage.shape[:3]))\n",
    "    except:\n",
    "        print('img file not found')\n",
    "        return None\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "# Test for image features\n",
    "generate_image_features(\"269898095_d00ac7d7a4.jpg\")\n",
    "\n",
    "def generate_text_samples(path, photos_per_batch, n_vocab):\n",
    "    \n",
    "    X, y = [], []\n",
    "    nr_photos = 0\n",
    "    \n",
    "    while True:\n",
    "        with open(path, 'r') as f:\n",
    "            for line in f:\n",
    "                nr_photos += 1\n",
    "                img_name = line.split(' ')[0].split('#')[0]\n",
    "                img_features = generate_image_features(img_name)\n",
    "                if img_features is None:\n",
    "                    continue\n",
    "                seq = line.split(' ')[1:]\n",
    "                text = \" \".join(seq)\n",
    "                seq = nltk.word_tokenize(text)\n",
    "                seq.insert(0, token_start)\n",
    "                seq.insert(len(seq), token_end)\n",
    "                seq = [token.lower() for token in seq]\n",
    "                \n",
    "                # split one sequence into multiple X, y pairs\n",
    "                for i in range(1, len(seq)):\n",
    "                    in_seq_em = []\n",
    "                    # add padding\n",
    "                    for j in range(max(0, seq_length - i - 1)):\n",
    "                        in_seq_em.append(np.float32([0] * img_embedding))\n",
    "                    # add image\n",
    "                    in_seq_em.append(img_features[0])\n",
    "                    # add text\n",
    "                    for j in range(max(i - seq_length + 1, 0), i):\n",
    "                        if seq[j] in model_embeddings.wv:\n",
    "                            in_seq_em.append(model_embeddings.wv[seq[j]])\n",
    "                        else:\n",
    "                            in_seq_em.append(model_embeddings.wv[special_token])\n",
    "                    in_seq_em = np.float32(in_seq_em)\n",
    "                    try:\n",
    "                        token_index = token_to_int[seq[i]]\n",
    "                    except:\n",
    "                        token_index = 0\n",
    "                    out_seq = np_utils.to_categorical([token_index], num_classes=n_vocab)[0]\n",
    "                    X.append(in_seq_em)\n",
    "                    y.append(out_seq)\n",
    "                # yield the batch data\n",
    "                if nr_photos == photos_per_batch:\n",
    "                    try:\n",
    "                        X = np.float32(X)\n",
    "                        X = X.reshape((X.shape[0], seq_length, img_embedding))\n",
    "                        y = np.float32(y)\n",
    "                        yield (X, np.float32(y))\n",
    "                    except:                    \n",
    "                        print('wrong batch shape')\n",
    "                    X, y = [], []\n",
    "                    nr_photos = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GenerateText(Callback):\n",
    "    # show some generated text at the end of each epoch (start always from <start>)\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        tokens_to_generate = 20\n",
    "        predictions = []\n",
    "        img_name = '1305564994_00513f9a5b.jpg'\n",
    "        Xp = np.zeros((1, seq_length, img_embedding))\n",
    "        # generate a sequence from starting from start sequence\n",
    "        for index_sample in range(tokens_to_generate):\n",
    "            if index_sample == 0:\n",
    "                start = token_start\n",
    "                predictions.append(token_to_int[start])\n",
    "                Xp[0, -2, :] = generate_image_features(img_name)[0]\n",
    "                # model_embeddings\n",
    "                Xp[0, -1, :] = np.float32(model_embeddings.wv[start])\n",
    "                Xp = np.float32(Xp).reshape((1, seq_length, img_embedding))\n",
    "            else:\n",
    "                # model_embeddings\n",
    "                added_word = int_to_token[last_pred]\n",
    "                if added_word in model_embeddings.wv:    \n",
    "                    next_token = np.float32(model_embeddings[added_word])\n",
    "                else:\n",
    "                    next_token = np.float32(model_embeddings[special_token])\n",
    "                # eliminate first char, add the last char predicted\n",
    "                Xp = np.append(Xp[0, 1:, :], next_token).reshape((1, seq_length, img_embedding))\n",
    "           \n",
    "            p = self.model.predict(x=Xp, batch_size=None, steps=1)[0]\n",
    "            last_pred = np.argmax(p)\n",
    "            predictions.append(last_pred)\n",
    "            \n",
    "            if int_to_token[last_pred] == token_end:\n",
    "                break\n",
    "        gen_sent = \" \".join([int_to_token[p] for p in predictions])\n",
    "        print('On epoch {} text generated: {}'.format(epoch, gen_sent))\n",
    "    \n",
    "#sequential model - not used\n",
    "# def sequential_model(X, y):\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(32, input_shape=(X.shape[1], X.shape[2])))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(y.shape[1], activation='softmax'))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     # define the checkpoint\n",
    "#     filepath=\"models/seq-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "#     checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "#     show_gen_txt = GenerateText()\n",
    "#     callbacks_list = [checkpoint, show_gen_txt]\n",
    "#     # fit the model\n",
    "#     print(model.summary())\n",
    "#     model.fit_generator(generate_text_samples(filepath, 5, n_vocab),\\\n",
    "#                         epochs=20, batch_size=128, callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "#sequential_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 17, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6689)              862881    \n",
      "=================================================================\n",
      "Total params: 1,082,529\n",
      "Trainable params: 1,082,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5000\n",
      "42/50 [========================>.....] - ETA: 1s - loss: 7.1552 - acc: 0.0990"
     ]
    }
   ],
   "source": [
    "\n",
    "# functional model \n",
    "def functional_model():\n",
    "    \n",
    "    inputt = Input(shape=(seq_length, img_embedding))\n",
    "    char_lstm_last_hidden_state = LSTM(units=lstm_cell,\\\n",
    "                                       input_shape=(seq_length, img_embedding),\\\n",
    "                                       return_sequences=False,\\\n",
    "                                       stateful=False)(inputt)\n",
    "    # TODO add Input() layer for photos\n",
    "    output = Dense(n_vocab, activation='softmax')(char_lstm_last_hidden_state)\n",
    "    model = keras.models.Model(inputs=inputt,\\\n",
    "                               outputs=output)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # define the checkpoint\n",
    "    filepath_save = \"models/weights-improvement-{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath_save, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    show_gen_txt = GenerateText()\n",
    "    callbacks_list = [checkpoint, show_gen_txt]\n",
    "    print(model.summary())\n",
    "    # fit the model\n",
    "    model.fit_generator(generate_text_samples(filepath, photos_per_batch, n_vocab),\\\n",
    "                        epochs=5000, steps_per_epoch=50,\\\n",
    "                        callbacks=callbacks_list, verbose=1)\n",
    "    \n",
    "functional_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
